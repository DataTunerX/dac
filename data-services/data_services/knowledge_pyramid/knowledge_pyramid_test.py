import os
import sys
import logging
import asyncio
from typing import List, Dict, Any

current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
sys.path.insert(0, project_root)

from data_services.knowledge_pyramid.knowledge_pyramid import KnowledgePyramidService
from data_services.api.base import DocumentModel, SearchType

logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

testdata = """
'`balance_sheet` è¡¨è®°å½•äº†å„åˆ†è¡Œåœ¨ç‰¹å®šæ—¥æœŸçš„è´¢åŠ¡çŠ¶å†µï¼ŒåŒ…æ‹¬æ€»èµ„äº§ã€å®¢æˆ·è´·æ¬¾ã€åŒä¸šèµ„äº§ã€å…¶ä»–èµ„äº§ã€æ€»è´Ÿå€ºã€å®¢æˆ·å­˜æ¬¾ã€åŒä¸šè´Ÿå€ºã€å…¶ä»–è´Ÿå€ºã€å®¢æˆ·æ€»æ•°ã€ä¸ªäººå®¢æˆ·æ•°ã€ä¼ä¸šå®¢æˆ·æ•°ã€åŒä¸šå®¢æˆ·æ•°åŠå‘˜å·¥æ€»æ•°ã€‚`deposit_data` è¡¨è¯¦ç»†åˆ—å‡ºäº†å„åˆ†è¡Œåœ¨ç‰¹å®šæ—¥æœŸçš„å­˜æ¬¾æƒ…å†µï¼Œæ¶µç›–å®¢æˆ·å­˜æ¬¾æ€»é¢ã€ä¼ä¸šå­˜æ¬¾æ€»é¢ã€ä¼ä¸šæ´»æœŸå­˜æ¬¾ã€ä¼ä¸šå®šæœŸå­˜æ¬¾ã€é›¶å”®å­˜æ¬¾æ€»é¢ã€é›¶å”®æ´»æœŸå­˜æ¬¾åŠé›¶å”®å®šæœŸå­˜æ¬¾ã€‚`loan_data` è¡¨æä¾›äº†å„åˆ†è¡Œåœ¨ç‰¹å®šæ—¥æœŸçš„è´·æ¬¾è¯¦æƒ…ï¼ŒåŒ…æ‹¬å®¢æˆ·è´·æ¬¾æ€»é¢ã€å®žè´¨æ€§è´·æ¬¾æ€»é¢ã€ä¼ä¸šè´·æ¬¾æ€»é¢ã€æ™®æƒ å°å¾®ä¼ä¸šè´·æ¬¾ã€é›¶å”®è´·æ¬¾æ€»é¢ã€ä¿¡ç”¨å¡è´·æ¬¾ã€ä¸­åž‹ä¼ä¸šè´·æ¬¾ã€å¤§åž‹ä¼ä¸šè´·æ¬¾ã€ä¸­åž‹åŠå°åž‹ä¼ä¸šè´·æ¬¾ã€å¤§åž‹ä¼ä¸šè´·æ¬¾ã€æ€»è´´çŽ°é¢ã€ç›´æŽ¥è´´çŽ°åŠè½¬è´´çŽ°ã€‚`retail_loan_detail` è¡¨åˆ™è¿›ä¸€æ­¥ç»†åˆ†äº†é›¶å”®è´·æ¬¾çš„å…·ä½“æž„æˆï¼Œå¦‚é›¶å”®è´·æ¬¾æ€»é¢ã€æŠµæŠ¼è´·æ¬¾æ€»é¢ã€ä¸€æ‰‹æˆ¿æŠµæŠ¼è´·æ¬¾ã€äºŒæ‰‹æˆ¿æŠµæŠ¼è´·æ¬¾åŠæ¶ˆè´¹è´·æ¬¾æ€»é¢ã€‚ \n\n \n## Table: `balance_sheet`\n\n| Column | Type | Nullable | Key | Comment |\n|--------|------|----------|-----|---------|\n| `data_date` | `date` | NO | PRI |  |\n| `branch_id` | `varchar(4)` | NO | PRI |  |\n| `branch_name` | `varchar(50)` | NO | PRI |  |\n| `total_assets` | `decimal(18,0)` | YES |  |  |\n| `customer_loans` | `decimal(18,0)` | YES |  |  |\n| `interbank_assets` | `decimal(18,0)` | YES |  |  |\n| `other_assets` | `decimal(18,0)` | YES |  |  |\n| `total_liabilities` | `decimal(18,0)` | YES |  |  |\n| `customer_deposits` | `decimal(18,0)` | YES |  |  |\n| `interbank_liabilities` | `decimal(18,0)` | YES |  |  |\n| `other_liabilities` | `decimal(18,0)` | YES |  |  |\n| `total_customers` | `int` | YES |  |  |\n| `individual_customers` | `int` | YES |  |  |\n| `corporate_customers` | `int` | YES |  |  |\n| `interbank_customers` | `int` | YES |  |  |\n| `total_employees` | `int` | YES |  |  |\n\n## Table: `deposit_data`\n\n| Column | Type | Nullable | Key | Comment |\n|--------|------|----------|-----|---------|\n| `data_date` | `date` | NO | PRI | YYYY/MM/DD |\n| `branch_id` | `varchar(4)` | NO | PRI | 4 |\n| `branch_name` | `varchar(50)` | NO | PRI |  |\n| `customer_deposit_total` | `decimal(18,0)` | YES |  | + |\n| `corporate_deposit_total` | `decimal(18,0)` | YES |  |  |\n| `corporate_current_deposit` | `decimal(18,0)` | YES |  |  |\n| `corporate_term_deposit` | `decimal(18,0)` | YES |  |  |\n| `retail_deposit_total` | `decimal(18,0)` | YES |  |  |\n| `retail_current_deposit` | `decimal(18,0)` | YES |  |  |\n| `retail_term_deposit` | `decimal(18,0)` | YES |  |  |\n\n## Table: `loan_data`\n\n| Column | Type | Nullable | Key | Comment |\n|--------|------|----------|-----|---------|\n| `data_date` | `date` | NO | PRI | YYYY/MM/DD |\n| `branch_id` | `varchar(4)` | NO | PRI | 4 |\n| `branch_name` | `varchar(50)` | NO | PRI |  |\n| `total_customer_loan` | `decimal(18,0)` | YES |  |  |\n| `substantive_loan_total` | `decimal(18,0)` | YES |  |  |\n| `corporate_loan_total` | `decimal(18,0)` | YES |  |  |\n| `inclusive_sme_loan` | `decimal(18,0)` | YES |  |  |\n| `retail_loan_total` | `decimal(18,0)` | YES |  |  |\n| `credit_card_loan` | `decimal(18,0)` | YES |  |  |\n| `medium_small_loan` | `decimal(18,0)` | YES |  |  |\n| `large_loan` | `decimal(18,0)` | YES |  |  |\n| `medium_small_corporate_loan` | `decimal(18,0)` | YES |  |  |\n| `large_corporate_loan` | `decimal(18,0)` | YES |  |  |\n| `total_discount` | `decimal(18,0)` | YES |  | + |\n| `direct_discount` | `decimal(18,0)` | YES |  |  |\n| `transfer_discount` | `decimal(18,0)` | YES |  |  |\n\n## Table: `retail_loan_detail`\n\n| Column | Type | Nullable | Key | Comment |\n|--------|------|----------|-----|---------|\n| `data_date` | `date` | NO | PRI | YYYY/MM/DD |\n| `branch_id` | `varchar(4)` | NO | PRI | 4 |\n| `branch_name` | `varchar(50)` | NO | PRI |  |\n| `retail_loan_total` | `decimal(18,2)` | YES |  |  |\n| `mortgage_total` | `decimal(18,2)` | YES |  |  |\n| `first_hand_mortgage` | `decimal(18,2)` | YES |  |  |\n| `second_hand_mortgage` | `decimal(18,2)` | YES |  |  |\n| `consumer_loan_total` | `decimal(18,2)` | YES |  |  | \n\n sample data:\n[\n  {\n    "table_name": "balance_sheet",\n    "sample_data": {\n      "data_date": "2023-11-30",\n      "branch_id": "9200",\n      "branch_name": "",\n      "total_assets": "113962000000",\n      "customer_loans": "51957000000",\n      "interbank_assets": "52900000000",\n      "other_assets": "9105000000",\n      "total_liabilities": "91641800000",\n      "customer_deposits": "46901000000",\n      "interbank_liabilities": "42800000000",\n      "other_liabilities": "1940800000",\n      "total_customers": 781347,\n      "individual_customers": 763683,\n      "corporate_customers": 17376,\n      "interbank_customers": 288,\n      "total_employees": 12378\n    }\n  },\n  {\n    "table_name": "deposit_data",\n    "sample_data": {\n      "data_date": "2023-11-30",\n      "branch_id": "9200",\n      "branch_name": "",\n      "customer_deposit_total": "46901000000",\n      "corporate_deposit_total": "22536300000",\n      "corporate_current_deposit": "15850250000",\n      "corporate_term_deposit": "6686050000",\n      "retail_deposit_total": "24364700000",\n      "retail_current_deposit": "16237920000",\n      "retail_term_deposit": "8126780000"\n    }\n  },\n  {\n    "table_name": "loan_data",\n    "sample_data": {\n      "data_date": "2023-11-30",\n      "branch_id": "9200",\n      "branch_name": "",\n      "total_customer_loan": "51957000000",\n      "substantive_loan_total": "41566850000",\n      "corporate_loan_total": "24108821500",\n      "inclusive_sme_loan": "10319317040",\n      "retail_loan_total": "7138711460",\n      "credit_card_loan": "2526750000",\n      "medium_small_loan": "17458028500",\n      "large_loan": "24108821500",\n      "medium_small_corporate_loan": "13416839645",\n      "large_corporate_loan": "10691981855",\n      "total_discount": "7863400000",\n      "direct_discount": "6028631000",\n      "transfer_discount": "1834769000"\n    }\n  },\n  {\n    "table_name": "retail_loan_detail",\n    "sample_data": {\n      "data_date": "2023-11-30",\n      "branch_id": "9200",\n      "branch_name": "",\n      "retail_loan_total": "7138711460.00",\n      "mortgage_total": "4446734585.20",\n      "first_hand_mortgage": "2223367292.60",\n      "second_hand_mortgage": "2223367292.60",\n      "consumer_loan_total": "2691976874.80"\n    }\n  }\n'
"""

class KnowledgePyramidTester:
    def __init__(self):
        self.test_collection = "test_knowledge_pyramid8"
        self.knowledge_service = KnowledgePyramidService()
        self.added_document_ids = []
        self.added_memory_ids = []

    def setup_environment(self):
        """Set up test environment variables"""
        os.environ.update({
            # Telemetry configuration
            'EC_TELEMETRY': 'False',
            'MEM0_TELEMETRY': 'False',
            
            # Embedding model configuration
            'EMBEDDING_PROVIDER': 'dashscope',
            'EMBEDDING_API_KEY': 'sk-xxx',
            'EMBEDDING_MODEL': 'text-embedding-v4',
            
            # LLM configuration
            'LLM_API_KEY': 'sk-xxx',
            'LLM_BASE_URL': 'https://dashscope.aliyuncs.com/compatible-mode/v1',
            'LLM_MODEL': 'deepseek-v3',
            'LLM_TEMPERATURE': '0.01',
            
            # Memory vector database configuration
            'MEMORY_PGVECTOR_HOST': '192.168.xxx.xxx',
            'MEMORY_PGVECTOR_PORT': '5433',
            'MEMORY_PGVECTOR_USER': 'postgres',
            'MEMORY_PGVECTOR_PASSWORD': 'postgres',
            'MEMORY_PGVECTOR_MIN_CONNECTION': '1',
            'MEMORY_PGVECTOR_MAX_CONNECTION': '10',
            'MEMORY_DBNAME': 'agent_memory',
            'MEMORY_COLLECTION': 'memories',
            'MEMORY_EMBEDDING_DIMS': '1024',
            
            # General vector database configuration (maintain backward compatibility)
            'PGVECTOR_HOST': '192.168.xxx.xxx',
            'PGVECTOR_PORT': '5433',
            'PGVECTOR_USER': 'postgres',
            'PGVECTOR_PASSWORD': 'postgres',
            'PGVECTOR_DATABASE': 'knowledge_vector',
            'PGVECTOR_MIN_CONNECTION': '1',
            'PGVECTOR_MAX_CONNECTION': '10',
            
            # Knowledge base vector database configuration
            'KNOWLEDGE_PGVECTOR_HOST': '192.168.xxx.xxx',
            'KNOWLEDGE_PGVECTOR_PORT': '5433',
            'KNOWLEDGE_PGVECTOR_USER': 'postgres',
            'KNOWLEDGE_PGVECTOR_PASSWORD': 'postgres',
            'KNOWLEDGE_PGVECTOR_MIN_CONNECTION': '1',
            'KNOWLEDGE_PGVECTOR_MAX_CONNECTION': '10',
            'KNOWLEDGE_MEMORY_DBNAME': 'knowledge_memories',
            'KNOWLEDGE_MEMORY_COLLECTION': 'knowledge_memories',
            'KNOWLEDGE_MEMORY_EMBEDDING_DIMS': '1024',

            # graph setting
            'KNOWLEDGE_MEMORY_GRAPH_ENABLE': 'disable',
            'KNOWLEDGE_MEMORY_GRAPH_DB_PROVIDER': 'neo4j',
            'KNOWLEDGE_MEMORY_GRAPH_DB_URL': "neo4j://192.168.xxx.xxx:7687",
            'KNOWLEDGE_MEMORY_GRAPH_DB_USERNAME': 'neo4j',
            'KNOWLEDGE_MEMORY_GRAPH_DB_PASSWORD': 'test123456',
            'KNOWLEDGE_MEMORY_GRAPH_LLM_MODEL': 'qwen2.5-72b-instruct',
            'KNOWLEDGE_MEMORY_GRAPH_LLM_APIKEY': 'sk-xxx',
            'KNOWLEDGE_MEMORY_GRAPH_LLM_BASEURL': 'https://dashscope.aliyuncs.com/compatible-mode/v1'
        })
        logger.info("Environment variables set")

    async def initialize_service(self):
        """Initialize knowledge pyramid service"""
        try:
            logger.info("Initializing Knowledge Pyramid Service...")
            await self.knowledge_service.initialize()
            logger.info("Knowledge Pyramid Service initialized successfully")
            return True
        except Exception as e:
            logger.error(f"Failed to initialize service: {str(e)}")
            return False

    def create_test_documents(self) -> List[DocumentModel]:
        """Create test documents"""
        return [
            DocumentModel(
                page_content="I'm not a big fan of thriller movies but I love sci-fi movies.",
                metadata={"category": "technology", "source": "wikipedia", "language": "english"}
            ),
            DocumentModel(
                page_content="æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿåœ¨æ²¡æœ‰æ˜Žç¡®ç¼–ç¨‹çš„æƒ…å†µä¸‹å­¦ä¹ å’Œæ”¹è¿›ã€‚",
                metadata={"category": "technology", "source": "academic", "language": "chinese"}
            )
        ]

        # Test SQL case
        # return [
        #     DocumentModel(
        #         page_content=testdata,
        #         metadata={"category": "technology", "source": "wikipedia", "language": "english"}
        #     )
        # ]

    async def test_add_documents(self):
        """Test adding documents to knowledge pyramid"""
        logger.info("===== Testing add_documents_with_knowledge_pyramid =====")
        
        test_documents = self.create_test_documents()
        
        try:
            result = await self.knowledge_service.add_documents_with_knowledge_pyramid1(
                collection_name=self.test_collection,
                documents=test_documents
            )
            
            logger.info(f"Add documents result: {result}")
            
            if result["status"] == "success":
                # Extract IDs based on actual return structure
                vector_results = result.get("vector_results", [])
                memory_result = result.get("memory_result", [])
                
                # Save document IDs (list of strings)
                if isinstance(vector_results, list) and all(isinstance(id, str) for id in vector_results):
                    self.added_document_ids = vector_results
                    logger.info(f"Document IDs: {self.added_document_ids}")
                else:
                    logger.warning(f"Unexpected vector_results format: {vector_results}")
                
                # Save memory IDs (extract id field from list of dictionaries)
                if isinstance(memory_result, list):
                    memory_ids = []
                    for memory_item in memory_result:
                        if isinstance(memory_item, dict) and 'id' in memory_item:
                            memory_ids.append(memory_item['id'])
                    self.added_memory_ids = memory_ids
                    logger.info(f"Memory IDs: {self.added_memory_ids}")
                else:
                    logger.warning(f"Unexpected memory_result format: {memory_result}")
                
                logger.info(f"Successfully added {len(test_documents)} documents")
                logger.info(f"Got {len(self.added_document_ids)} document IDs")
                logger.info(f"Got {len(self.added_memory_ids)} memory IDs")
                return True
            else:
                logger.error(f"Failed to add documents: {result.get('message', 'Unknown error')}")
                return False
                
        except Exception as e:
            logger.error(f"Error in add_documents test: {str(e)}")
            return False

    async def test_search_documents(self):
        """Test searching documents"""
        logger.info("===== Testing search_documents_with_knowledge_pyramid =====")
        
        try:
            result = await self.knowledge_service.search_documents_with_knowledge_pyramid(
                query="æœºå™¨å­¦ä¹ ",
                collection_name=self.test_collection,
                search_type=SearchType.VECTOR,
                limit=10
            )
            
            logger.info(f"Search result status: {result['status']}")
            
            if result["status"] == "success":
                vector_results = result.get("vector_result", [])
                memory_results = result.get("memory_result", [])
                logger.info(f"Found {len(vector_results)} vector results")
                logger.info(f"Found {len(memory_results)} memory results")
                
                # Display some search result details
                if vector_results:
                    for i, doc in enumerate(vector_results[:2]):  # Only show first 2
                        logger.info(f"Vector result {i+1}: {doc.get('content', '')[:100]}...")
                        logger.info(f"  Score: {doc.get('score', 0)}, Metadata: {doc.get('metadata', {})}")
                
                if memory_results:
                    for i, mem in enumerate(memory_results[:2]):  # Only show first 2
                        logger.info(f"Memory result {i+1}: {mem.get('memory', '')[:100]}...")
                        logger.info(f"  Score: {mem.get('score', 0)}")
                
                return True
            else:
                logger.error(f"Search failed: {result.get('message', 'Unknown error')}")
                return False
                    
        except Exception as e:
            logger.error(f"Error in search test: {str(e)}")
            return False

    async def test_search_memory_documents(self):
        """Test searching memory documents with knowledge pyramid"""
        logger.info("===== Testing search_memory_documents_with_knowledge_pyramid =====")
        
        try:
            result = await self.knowledge_service.search_memory_documents_with_knowledge_pyramid(
                collection_name=self.test_collection
            )
            
            logger.info(f"Search memory documents result status: {result}")
            
            if result["status"] == "success":
                collection = result.get("collection", "")
                memory_result = result.get("memory_result", [])
                
                logger.info(f"Collection: {collection}")
                logger.info(f"Found {len(memory_result)} memory results")
                
                # Display memory results details
                if memory_result:
                    logger.info("Memory results (sorted by score ascending):")
                    for i, memory in enumerate(memory_result):
                        logger.info(f"Memory {i+1}:")
                        logger.info(f"  ID: {memory.get('id', 'N/A')}")
                        logger.info(f"  Score: {memory.get('score', 0)}")
                        logger.info(f"  Content: {memory.get('memory', '')[:100]}..." if memory.get('memory') else "  Content: N/A")
                        
                        # Log additional metadata if available
                        metadata = memory.get('metadata', {})
                        if metadata:
                            logger.info(f"  Metadata: {metadata}")
                        
                        # Only show first 3 results to avoid log spam
                        if i >= 2:
                            remaining = len(memory_result) - 3
                            if remaining > 0:
                                logger.info(f"  ... and {remaining} more memory results")
                            break
                
                # Verify the sorting (should be ascending order by score)
                if len(memory_result) >= 2:
                    scores = [mem.get('score', 0) for mem in memory_result]
                    is_sorted_ascending = all(scores[i] <= scores[i+1] for i in range(len(scores)-1))
                    logger.info(f"Memory results sorted ascending by score: {is_sorted_ascending}")

                    if not is_sorted_ascending:
                        logger.warning("Memory results are not properly sorted by score ascending")
                return True
            else:
                logger.error(f"Search memory documents failed: {result.get('message', 'Unknown error')}")
                return False
                    
        except Exception as e:
            logger.error(f"Error in search memory documents test: {str(e)}")
            return False

    async def test_delete_documents_by_ids(self):
        """Test deleting documents and memories by IDs"""
        logger.info("===== Testing delete_documents_and_memorys_by_ids =====")
        
        if not self.added_document_ids:
            logger.error("No document IDs available for deletion test")
            return False
        
        if not self.added_memory_ids:
            logger.error("No memory IDs available for deletion test")
            return False
        
        try:
            # Use actual obtained IDs for testing
            logger.info(f"Deleting document IDs: {self.added_document_ids[:1]}")  # Only delete first one
            logger.info(f"Deleting memory IDs: {self.added_memory_ids[:1]}")     # Only delete first one
            
            result = await self.knowledge_service.delete_documents_and_memorys_by_ids(
                collection_name=self.test_collection,
                documents=self.added_document_ids[:1],  # Only delete first document
                memorys=self.added_memory_ids[:1]       # Only delete first memory
            )
            
            logger.info(f"Delete by IDs result: {result}")
            
            if result["status"] == "success":
                logger.info("âœ… Delete by IDs operation completed successfully")
                
                # Verify deletion effect
                await asyncio.sleep(1)
                logger.info("Verifying deletion by searching again...")
                
                search_result = await self.knowledge_service.search_documents_with_knowledge_pyramid(
                    query="æœºå™¨å­¦ä¹ ",
                    collection_name=self.test_collection,
                    search_type=SearchType.VECTOR,
                    limit=10
                )
                
                logger.info(f"Remaining after deletion: {search_result}")
                
                return True
            else:
                logger.error(f"Failed to delete by IDs: {result.get('message', 'Unknown error')}")
                return False
                
        except Exception as e:
            logger.error(f"Error in delete by IDs test: {str(e)}")
            return False

    async def test_delete_all_documents(self):
        """Test deleting all documents and memories"""
        logger.info("===== Testing delete_all_documents_and_memorys_by_collection_name =====")
        
        # First ensure there is some data
        if not self.added_document_ids:
            logger.info("Adding test documents first...")
            if not await self.test_add_documents():
                return False
            await asyncio.sleep(2)
        
        try:
            result = await self.knowledge_service.delete_all_documents_and_memorys_by_collection_name(
                collection_name=self.test_collection
            )
            
            logger.info(f"Delete all result: {result}")
            
            if result["status"] == "success":
                logger.info(f"âœ… Successfully deletion of all documents from collection: {self.test_collection}")
                return True
            else:
                logger.error(f"Failed to delete all: {result.get('message', 'Unknown error')}")
                return False
                
        except Exception as e:
            logger.error(f"Error in delete all test: {str(e)}")
            return False

    async def run_all_tests(self):
        """Run all tests"""
        logger.info("Starting Knowledge Pyramid Service tests...")
        
        try:
            self.setup_environment()
            
            if not await self.initialize_service():
                return False
            
            # # Test 1: Adding documents
            # logger.info("\n" + "="*50)
            # logger.info("TEST 1: Adding Documents")
            # logger.info("="*50)
            # if not await self.test_add_documents():
            #     return False
            
            # await asyncio.sleep(2)
            
            # # Test 2: Searching documents
            # logger.info("\n" + "="*50)
            # logger.info("TEST 2: Searching Documents")
            # logger.info("="*50)
            # if not await self.test_search_documents():
            #     return False
            
            # await asyncio.sleep(1)

            # Test 3: Searching memories documents
            logger.info("\n" + "="*50)
            logger.info("TEST 2: Searching memory Documents")
            logger.info("="*50)
            if not await self.test_search_memory_documents():
                return False
            
            await asyncio.sleep(1)
            
            # # Test 4: Deleting by IDs
            # logger.info("\n" + "="*50)
            # logger.info("TEST 3: Deleting by IDs")
            # logger.info("="*50)
            # if not await self.test_delete_documents_by_ids():
            #     return False
            
            # await asyncio.sleep(1)
            
            # # Re-add documents for full deletion test
            # logger.info("\n" + "="*50)
            # logger.info("Re-adding documents for full deletion test")
            # logger.info("="*50)
            # if not await self.test_add_documents():
            #     return False
            
            # await asyncio.sleep(2)
            
            # # Test 5: Deleting all
            # logger.info("\n" + "="*50)
            # logger.info("TEST 4: Deleting All Documents")
            # logger.info("="*50)
            # if not await self.test_delete_all_documents():
            #     return False
            
            logger.info("\n" + "="*50)
            logger.info("âœ… All tests passed successfully!")
            logger.info("="*50)
            return True
            
        except Exception as e:
            logger.error(f"Test failed with error: {str(e)}")
            return False

async def main():
    """Main function"""
    tester = KnowledgePyramidTester()
    success = await tester.run_all_tests()
    
    if success:
        logger.info("ðŸŽ‰ All tests passed!")
        return 0
    else:
        logger.error("âŒ Tests failed!")
        return 1

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
